{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_neural_network_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3b8CEiJNG18"
      },
      "source": [
        "# 02. Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkU2O7e0QMPV"
      },
      "source": [
        "classification problem : binary classification : is it one thing or another\n",
        "\n",
        "Is it a spam or not a spam\n",
        "\n",
        "Multiclass classification : is it a photo of a pizza, sushi or steak (we can have any number of classes). One photo, one classification among many\n",
        "\n",
        "Multilabel classification: Predict what categories should be assigned to a Wikipedia article. One sample, multiple labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYdj6Rp_Pxrk"
      },
      "source": [
        "### what are we going to cover\n",
        "\n",
        "\n",
        "* Architecture of a classification model\n",
        "* Input shapes and output shapes\n",
        "* Creating custom data to view and fit\n",
        "* Steps in modelling for binary and mutliclass classification\n",
        "* The power of non-linearity\n",
        "* Evaluating classification models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvTO24l4QH63"
      },
      "source": [
        "### Typical architecture of a classification neural network\n",
        "\n",
        "* An input layer\n",
        "* Some hidden layers\n",
        "* An output layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxdcNd18Qh46"
      },
      "source": [
        "<table>\n",
        "<thead><tr><td>Hyperparameter</td><td>Binary Classification</td><td>Multiclass classification</td></tr></thead>\n",
        "<tbody><tr><td>Input layer shape</td><td>Same as number of features (e.g. 5 for age, sex, height, weight, smoking status in heart disease prediction)</td><td>Same as binary classification</td></tr>\n",
        "<tr><td>Hidden layer(s)</td><td>Problem specific, minimum = 1, maximum = unlimited</td><td>Same as binary classification</td></tr>\n",
        "<tr><td>Neurons per hidden layer</td><td>Problem specific, generally 10 to 100</td><td>Same as binary classification</td></tr>\n",
        "<tr><td>Output layer shape \t</td><td>1 (one class or the other) \t</td><td>1 per class (e.g. 3 for food, person or dog photo)</td></tr>\n",
        "<tr><td>Hidden activation \t</td><td>Usually ReLU (rectified linear unit) \t</td><td>Same as binary classification</td></tr>\n",
        "<tr><td>Output activation \t</td><td>Sigmoid \t</td><td>Softmax</td></tr>\n",
        "<tr><td>Loss function \t</td><td>Cross entropy (tf.keras.losses.BinaryCrossentropy in TensorFlow) \t</td><td>Cross entropy (tf.keras.losses.CategoricalCrossentropy in TensorFlow)</td></tr>\n",
        "<tr><td>Optimizer \t</td><td>SGD (stochastic gradient descent), Adam \t</td><td>Same as binary classification</td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\n",
        "Table 1: Typical architecture of a classification network. Source: Adapted from page 295 of Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bu-3yElSNuq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}